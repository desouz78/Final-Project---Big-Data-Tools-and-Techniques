{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6649e1",
   "metadata": {},
   "source": [
    "# Notebook regarding the Final Project of Big Data Tools and Techniques.\n",
    "\n",
    "- Rowan University - Fall 2025\n",
    "- Student's name: **Luciano Stork (916547334)**\n",
    "- Professor: Dr. Silvija Kokalj-Filipovic\n",
    "\n",
    "\n",
    "The purpose of this work is to visually present how rural public schools with data connections, categorized by access technology and service provider, are distributed across the national territory. To this end, I will use Neo4J Database to illustrate this distribution based on the Brazilian states.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067c20f",
   "metadata": {},
   "source": [
    "## 1) Data Collection:\n",
    "\n",
    "Note:\n",
    "- The file \"Relacao_Escolas_Rurais_Atendidas.csv\" was originally collected from the official website of the Brazilian National Telecommunications Agency (Anatel) via the following URL: https://dados.gov.br/dados/conjuntos-dados/escolas-rurais-conectadas\n",
    "\n",
    "\n",
    "- However, security limitations prevented me from obtaining the direct download URL from the aforementioned site. As a solution, I uploaded the file to my personal Cloud Drive and from there I was able to download it to my local machine.\n",
    "\n",
    " * Link to access the file via my Cloud Drive: https://drive.google.com/file/d/1FFW_zLlqF8W7RX166bapVM0IH7fe3PKD/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297ff235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1FFW_zLlqF8W7RX166bapVMpIH7fe3PKD\n",
      "To: /Users/desouz78/Documents/studying/Big Data Tools and Techniques/FinalProject/Relacao_Escolas_Rurais_Atendidas.csv\n",
      "100%|██████████| 12.2M/12.2M [00:11<00:00, 1.04MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# first, install gdown if you haven't already\n",
    "# !pip install gdown\n",
    "\n",
    "import gdown # type: ignore\n",
    "\n",
    "# shared file link\n",
    "file_id = \"1FFW_zLlqF8W7RX166bapVMpIH7fe3PKD\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# local file name\n",
    "output = \"Relacao_Escolas_Rurais_Atendidas.csv\"\n",
    "\n",
    "# download the file\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "print(\"Download completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a9592",
   "metadata": {},
   "source": [
    "## 2) Visualize the data \n",
    "\n",
    "Note:\n",
    "- Given that this is a database collected and processed by a Brazilian federal organization, it is reasonable to assume that the data received considerable attention in terms of prior confirmation and verification before being shared. This explains its consistency, as there are no duplicate, empty, or inconsistent entries.\n",
    "\n",
    "- Therefore, on my part, no data processing was necessary beyond a visual and logical review of the records.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f8f549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29012 entries, 0 to 29011\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   NomePrestadora      29012 non-null  object\n",
      " 1   CodINEP             29012 non-null  object\n",
      " 2   siglaUf             29012 non-null  object\n",
      " 3   NomeMunicipio       29012 non-null  object\n",
      " 4   DescSituacao        29012 non-null  object\n",
      " 5   TipoObrigacao       29012 non-null  object\n",
      " 6   VelAcessoInstalada  29012 non-null  object\n",
      " 7   DescTecnologia      29012 non-null  object\n",
      " 8   NomeEscola          29012 non-null  object\n",
      " 9   DescTipoEscola      29012 non-null  object\n",
      " 10  DataAtivacao        29012 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "\n",
      "=== First 5 rows ===\n",
      "  NomePrestadora      CodINEP siglaUf       NomeMunicipio DescSituacao             TipoObrigacao VelAcessoInstalada DescTecnologia                NomeEscola DescTipoEscola DataAtivacao\n",
      "0    50417424566  32000022[*]      ES  Água Doce do Norte    Instalada  Rural  Edital 4G    ...         0.256 Mbps       SATÉLITE     EP FAZENDA JOAO NOHIA      Municipal   31/03/2016\n",
      "1    50417424566  32000030[*]      ES  Água Doce do Norte    Instalada  Rural  Edital 4G    ...         0.256 Mbps       SATÉLITE          EP SAO SEBASTIAO      Municipal   16/09/2016\n",
      "2    50417424566  32000049[*]      ES  Água Doce do Norte    Instalada  Rural  Edital 4G    ...         0.256 Mbps       SATÉLITE  EMPG JOAO ANTONIO MOR...      Municipal   31/07/2015\n",
      "3    50417424566  32000138[*]      ES  Água Doce do Norte    Instalada  Rural  Edital 4G    ...         0.256 Mbps       SATÉLITE   EU CORREGO SAO DOMINGOS      Municipal   23/11/2015\n",
      "4    50417424566  32000464[*]      ES  Água Doce do Norte    Instalada  Rural  Edital 4G    ...         0.256 Mbps       SATÉLITE   EMPEF PROF JOAO BATISTA      Municipal   19/11/2015\n",
      "\n",
      "=== Shape ===\n",
      "Rows: 29012, Columns: 11\n",
      "\n",
      "=== Missing values per column ===\n",
      "NomePrestadora        0\n",
      "CodINEP               0\n",
      "siglaUf               0\n",
      "NomeMunicipio         0\n",
      "DescSituacao          0\n",
      "TipoObrigacao         0\n",
      "VelAcessoInstalada    0\n",
      "DescTecnologia        0\n",
      "NomeEscola            0\n",
      "DescTipoEscola        0\n",
      "DataAtivacao          0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "=== Unique values per column ===\n",
      "NomePrestadora: 4 unique values\n",
      "CodINEP: 29008 unique values\n",
      "siglaUf: 27 unique values\n",
      "NomeMunicipio: 3940 unique values\n",
      "DescSituacao: 1 unique values\n",
      "TipoObrigacao: 1 unique values\n",
      "VelAcessoInstalada: 780 unique values\n",
      "DescTecnologia: 4 unique values\n",
      "NomeEscola: 27372 unique values\n",
      "DescTipoEscola: 4 unique values\n",
      "DataAtivacao: 1397 unique values\n"
     ]
    }
   ],
   "source": [
    "# Install pandas if you haven't yet\n",
    "#!pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "csv_file = \"Relacao_Escolas_Rurais_Atendidas.csv\"\n",
    "df = pd.read_csv(csv_file, encoding=\"latin1\", sep=\";\")\n",
    "\n",
    "# Optional: limit display widths to avoid line breaks\n",
    "pd.set_option('display.max_columns', None)     # show all columns\n",
    "pd.set_option('display.max_colwidth', 25)     # limit width of each column\n",
    "pd.set_option('display.width', 150)           # total display width\n",
    "pd.set_option('display.expand_frame_repr', False)  # prevent line wrapping\n",
    "\n",
    "# 1️⃣ Basic overview\n",
    "print(\"=== Basic Info ===\")\n",
    "print(df.info())        # data types, non-null counts\n",
    "print(\"\\n=== First 5 rows ===\")\n",
    "print(df.head())        # first rows\n",
    "print(\"\\n=== Shape ===\")\n",
    "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "\n",
    "# 2️⃣ Check for missing values\n",
    "print(\"\\n=== Missing values per column ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 3️⃣ Check for duplicate rows\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {num_duplicates}\")\n",
    "\n",
    "# 4️⃣ Check for inconsistent or suspicious data\n",
    "print(\"\\n=== Unique values per column ===\")\n",
    "for col in df.columns:\n",
    "    unique_vals = df[col].nunique()\n",
    "    print(f\"{col}: {unique_vals} unique values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3adac",
   "metadata": {},
   "source": [
    "## 3) Connect with Neo4J Database and Upload Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884d7147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/cnsw28bs7j34_n66kkvx0qhw0000gq/T/ipykernel_27272/3109590119.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Load the CSV\n",
    "csv_file = \"Relacao_Escolas_Rurais_Atendidas.csv\"\n",
    "df = pd.read_csv(csv_file, sep=\";\", encoding=\"latin1\")\n",
    "\n",
    "# Strip whitespace from string columns\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Connect to Neo4j Aura\n",
    "uri = \"neo4j+s://b6992aaa.databases.neo4j.io\"\n",
    "user = \"neo4j\"\n",
    "password = \"Ll0OGnyjEEGGdr6N8XWuDM-eoxERJjNmQP7kZHH1JCk\"\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "# Function to insert one row as nodes + relationships\n",
    "def insert_row(tx, row):\n",
    "\n",
    "    # Merge State\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (s:State {sigla: $siglaUf})\n",
    "        \"\"\",\n",
    "        siglaUf=row[\"siglaUf\"]\n",
    "    )\n",
    "\n",
    "    # Merge City with composite identity (city + state)\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (c:City {\n",
    "            name: $city,\n",
    "            state: $siglaUf\n",
    "        })\n",
    "        WITH c\n",
    "        MATCH (s:State {sigla: $siglaUf})\n",
    "        MERGE (s)-[:HAS_CITY]->(c)\n",
    "        \"\"\",\n",
    "        city=row[\"NomeMunicipio\"],\n",
    "        siglaUf=row[\"siglaUf\"]\n",
    "    )\n",
    "\n",
    "    # Merge School using CodINEP as unique identifier\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (sch:School {CodINEP: $CodINEP})\n",
    "        SET sch.name = $school_name,\n",
    "            sch.DescTipoEscola = $DescTipoEscola\n",
    "        WITH sch\n",
    "        MATCH (c:City {\n",
    "            name: $city,\n",
    "            state: $siglaUf\n",
    "        })\n",
    "        MERGE (c)-[:HAS_SCHOOL]->(sch)\n",
    "        \"\"\",\n",
    "        CodINEP=row[\"CodINEP\"],\n",
    "        school_name=row[\"NomeEscola\"],\n",
    "        DescTipoEscola=row[\"DescTipoEscola\"],\n",
    "        city=row[\"NomeMunicipio\"],\n",
    "        siglaUf=row[\"siglaUf\"]\n",
    "    )\n",
    "\n",
    "    # Merge Technology and relationship with properties\n",
    "    tx.run(\n",
    "        \"\"\"\n",
    "        MERGE (tech:Technology {name: $technology})\n",
    "        WITH tech\n",
    "        MATCH (sch:School {CodINEP: $CodINEP})\n",
    "        MERGE (sch)-[r:USES_TECHNOLOGY]->(tech)\n",
    "        SET r.DescSituacao = $DescSituacao,\n",
    "            r.TipoObrigacao = $TipoObrigacao,\n",
    "            r.VelAcessoInstalada = $VelAcessoInstalada,\n",
    "            r.NomePrestadora = $NomePrestadora,\n",
    "            r.DataAtivacao = $DataAtivacao\n",
    "        \"\"\",\n",
    "        technology=row[\"DescTecnologia\"],\n",
    "        CodINEP=row[\"CodINEP\"],\n",
    "        DescSituacao=row[\"DescSituacao\"],\n",
    "        TipoObrigacao=row[\"TipoObrigacao\"],\n",
    "        VelAcessoInstalada=row[\"VelAcessoInstalada\"],\n",
    "        NomePrestadora=row[\"NomePrestadora\"],\n",
    "        DataAtivacao=row[\"DataAtivacao\"]\n",
    "    )\n",
    "\n",
    "# Upload all rows\n",
    "with driver.session() as session:\n",
    "    for _, row in df.iterrows():\n",
    "        session.execute_write(insert_row, row)\n",
    "\n",
    "print(\"All rows uploaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
